{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1fc078dc-e44e-4254-8348-5e59c66669ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import tiktoken\n",
    "from dataclasses import dataclass\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "import random\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5e3ecd-0d98-4b91-84b9-fa2a9937e3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d414fd-c142-46c2-9b34-833aa549a41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shafneaz\\AppData\\Local\\Temp\\ipykernel_13460\\1802452005.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sentiment'].replace('positive', 0, inplace=True)\n",
      "C:\\Users\\shafneaz\\AppData\\Local\\Temp\\ipykernel_13460\\1802452005.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sentiment'].replace('negative', 1, inplace=True)\n",
      "C:\\Users\\shafneaz\\AppData\\Local\\Temp\\ipykernel_13460\\1802452005.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment'].replace('negative', 1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          0\n",
       "1  A wonderful little production. <br /><br />The...          0\n",
       "2  I thought this was a wonderful way to spend ti...          0\n",
       "3  Basically there's a family where a little boy ...          1\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].replace('positive', 0, inplace=True)\n",
    "df['sentiment'].replace('negative', 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fe8ea8-fae3-4ed3-aa00-c66a9841a2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          0\n",
       "1  A wonderful little production. The filming tec...          0\n",
       "2  I thought this was a wonderful way to spend ti...          0\n",
       "3  Basically there's a family where a little boy ...          1\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pre_process_text(text):\n",
    "    text = text.replace('<br />', \"\")\n",
    "    text = text.strip()\n",
    "    return text\n",
    "df['review'] = df['review'].apply(pre_process_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "df48289c-e57a-4b84-a43e-844bfd270794",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    block_size: int = 1024\n",
    "    batch_size: int = 16\n",
    "    model_name = 'gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5cc58a84-a5f0-4b5c-895b-2f2d3c0b77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_tokens(model_name, block_size):\n",
    "    encoder = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    tokens, labels = [], []\n",
    "    for indx, row in df.iterrows():\n",
    "        if not isinstance(row['review'], str):\n",
    "            continue\n",
    "        curr_tokens = encoder.encode(row['review'], max_length=block_size, add_special_tokens=True, truncation=True)\n",
    "        if len(curr_tokens) > block_size: \n",
    "            curr_tokens = curr_tokens[:block_size]\n",
    "        else: \n",
    "            curr_tokens = curr_tokens + [encoder.eos_token_id] * (block_size - len(curr_tokens))\n",
    "        tokens.append(curr_tokens)\n",
    "        labels.append(row['sentiment'])\n",
    "    return torch.tensor(tokens, dtype=torch.long), torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70d98d13-f037-411d-8821-32914a43e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "tokens, labels = convert_text_to_tokens(Config().model_name, config.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "937930a1-2d46-43d9-bfdb-1f7a1fbc3035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "# print(labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06b0d8eb-9e39-432f-a436-4be18edc234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(train_ratio, val_ratio):\n",
    "    test_ratio = 1 - train_ratio - val_ratio\n",
    "    indices_map = {}\n",
    "    train_indx, val_indx, test_indx = [], [], []\n",
    "    for indx, label in enumerate(labels):\n",
    "        label = label.item()\n",
    "        indices_map.setdefault(label, []).append(indx)\n",
    "    for key, val in indices_map.items():\n",
    "        shuffled_labels = val.copy()\n",
    "        random.shuffle(shuffled_labels)\n",
    "        train_num = int(len(shuffled_labels) * train_ratio)\n",
    "        val_num = int(len(shuffled_labels) * val_ratio)\n",
    "\n",
    "        train_indx.extend(shuffled_labels[:train_num])\n",
    "        val_indx.extend(shuffled_labels[train_num: train_num + val_num])\n",
    "        test_indx.extend(shuffled_labels[train_num + val_num:])\n",
    "\n",
    "    return tokens[train_indx], labels[train_indx], tokens[val_indx], labels[val_indx], tokens[test_indx], labels[test_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4353d16c-5fd2-4b56-a1cb-11db666705b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = train_test_val_split(0.70, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c663d401-e2e5-45b1-8db1-8eadee568607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0: 17500\n",
      "Count of 1: 17500\n"
     ]
    }
   ],
   "source": [
    "def shuffle_train_data(tr_data, tr_labels):\n",
    "    # shuffle train data\n",
    "    train_indices = torch.randperm(len(tr_data))\n",
    "    return tr_data[train_indices], tr_labels[train_indices]\n",
    "train_data, train_labels = shuffle_train_data(train_data, train_labels)\n",
    "count_zeros = (train_labels == 0).sum().item()\n",
    "count_ones = (train_labels == 1).sum().item()\n",
    "\n",
    "print(\"Count of 0:\", count_zeros)\n",
    "print(\"Count of 1:\", count_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "247060ff-88ba-4728-a4c7-6146fed57e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c55d5b3f-2b06-488e-990b-ed8979f22158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoaderLite:\n",
    "    def __init__(self, split, config):\n",
    "        self.config = config\n",
    "        if split in 'train':\n",
    "            self.data, self.labels = train_data, train_labels\n",
    "        elif split in 'val': \n",
    "            self.data, self.lables = val_data, val_labels\n",
    "        else:\n",
    "            self.data, self.labels = test_data, test_labels\n",
    "        self.current_indx = 0\n",
    "    def next_batch(self):\n",
    "        nxt_data, nxt_labels = self.data[self.current_indx: self.current_indx + self.config.batch_size], self.labels[self.current_indx: self.current_indx + self.config.batch_size]\n",
    "        self.current_indx += self.config.batch_size\n",
    "        if self.current_indx + self.config.batch_size > len(self.data):\n",
    "            self.current_indx = 0\n",
    "        return nxt_data, nxt_labels\n",
    "    def reset(self):\n",
    "        self.current_indx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "23033d83-9e6a-4325-94a2-d80cb98c6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = dataLoaderLite('train', Config()), dataLoaderLite('val', Config()), dataLoaderLite('test', Config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a2f67ad3-f5e9-46a3-b79a-dfcd4602929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.reset()\n",
    "val_loader.reset()\n",
    "test_loader.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "41c5be84-e4bb-4675-b110-0a215bb938e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Classifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.gpt2_model = GPT2Model.from_pretrained(self.config.model_name)\n",
    "        for param in self.gpt2_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for block in self.gpt2_model.h[-3:]:\n",
    "            for param in block.parameters(): \n",
    "                param.requires_grad = True\n",
    "        for param in self.gpt2_model.ln_f.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.classifier = nn.Linear(self.gpt2_model.config.n_embd, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x, attention_mask):\n",
    "        outputs = self.gpt2_model(x, attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state \n",
    "\n",
    "        # Use hidden state at the last non-padding token (EOS-style pooling)\n",
    "        seq_lengths = attention_mask.sum(dim=1) - 1\n",
    "        pooled = hidden_states[torch.arange(input_ids.size(0), device=input_ids.device), seq_lengths]\n",
    "\n",
    "        pooled = self.dropout(pooled)\n",
    "        return self.classifier(pooled)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7418be5d-770a-402d-8bce-2c2e3c14fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available(): \n",
    "    device = 'cuda'\n",
    "print(f\"using device {device}\")\n",
    "raw_model = GPT2Classifier(Config())\n",
    "raw_model.to(device)\n",
    "model = torch.compile(raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3564086c-6912-40a2-8e71-50977d434858",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 2e-5\n",
    "min_lr = max_lr * 0.01\n",
    "warmup_steps = 200\n",
    "max_steps = 2500\n",
    "total_grad_steps = 1 << 16\n",
    "weight_decay = 0.1\n",
    "grad_accum_steps = total_grad_steps // (Config().block_size * Config().batch_size)\n",
    "\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_steps:\n",
    "        return max_lr * (it+1) / warmup_steps\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > max_steps:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
    "    return min_lr + coeff * (max_lr - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ce30e117-dd11-4ff3-83e0-644f19661ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_optimizer(model, lr, weight_decay):\n",
    "    param_group = {pn:p for pn, p in model.named_parameters()}\n",
    "    param_group = {pn: p for pn, p in param_group.items() if p.requires_grad}\n",
    "\n",
    "    decay_params = [p for pn, p in param_group.items() if p.dim() >= 2]\n",
    "    non_decay_params = [p for pn, p in param_group.items() if p.dim() < 2]\n",
    "\n",
    "    optim_group = [\n",
    "        {\"params\": decay_params, \"weight_decay\": weight_decay}, \n",
    "        {\"params\": non_decay_params, \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    is_fused = \"cuda\" in device and fused_available\n",
    "    optimizer = torch.optim.AdamW(optim_group, lr=lr, fused=is_fused)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd68365-4ffb-47c0-b0bf-0fc598c172f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
