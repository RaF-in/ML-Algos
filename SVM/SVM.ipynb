{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6c4274-767b-41c4-b981-01a145a966d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 100.0\n",
      "Epoch 100, Cost: 20.32960716139212\n",
      "Epoch 200, Cost: 17.61118177311487\n",
      "Epoch 300, Cost: 16.753774496892895\n",
      "Epoch 400, Cost: 16.519451587866495\n",
      "Epoch 500, Cost: 16.429091284182604\n",
      "Epoch 600, Cost: 16.40927766008624\n",
      "Epoch 700, Cost: 16.40137942546569\n",
      "Epoch 800, Cost: 16.394639572562525\n",
      "Epoch 900, Cost: 16.38901901800932\n",
      "Training Accuracy: 99.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data (for demonstration)\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)  # 100 samples, 2 features\n",
    "Y = np.where((X[:, 0] + X[:, 1]) > 0, 1, -1)  # Labels: 1 or -1\n",
    "Y = Y.reshape(-1, 1)  # Reshape to column vector\n",
    "\n",
    "# Add bias term to X\n",
    "X = np.hstack((X, np.ones((X.shape[0], 1))))  # Extended feature matrix (X')\n",
    "\n",
    "# Hyperparameters\n",
    "C = 1.0  # Regularization parameter\n",
    "learning_rate = 0.001  # Learning rate\n",
    "epochs = 1000  # Number of iterations\n",
    "\n",
    "# Initialize combined W' (including W and b)\n",
    "W = np.zeros((X.shape[1], 1))  # Shape: (features + 1, 1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Calculate the hinge loss\n",
    "    linear_output = np.dot(X, W)  # Shape: (n_samples, 1)\n",
    "    hinge_loss = 1 - Y * linear_output  # Shape: (n_samples, 1)\n",
    "    hinge_loss = np.maximum(0, hinge_loss)  # ReLU: max(0, hinge_loss)\n",
    "\n",
    "    # Calculate the cost function\n",
    "    cost = 0.5 * np.dot(W[:-1].T, W[:-1]) + C * np.sum(hinge_loss)\n",
    "    cost = cost.flatten()[0]  # Convert to scalar for printing (optional)\n",
    "\n",
    "    # Calculate gradients\n",
    "    I = (hinge_loss > 0).astype(int)  # Indicator: 1 if hinge loss > 0, else 0\n",
    "    dW = W - C * np.dot(X.T, Y * I)  # Gradient w.r.t. W'\n",
    "\n",
    "    # Update W' using gradient descent\n",
    "    W -= learning_rate * dW\n",
    "\n",
    "    # Print cost (optional)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Cost: {cost}\")\n",
    "\n",
    "# Prediction function\n",
    "def predict(X, W):\n",
    "    X = np.hstack((X, np.ones((X.shape[0], 1))))  # Add bias term to X\n",
    "    linear_output = np.dot(X, W)\n",
    "    return np.sign(linear_output)\n",
    "\n",
    "# Test the model\n",
    "predictions = predict(X[:, :-1], W)  # Remove bias column from X for prediction\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = np.mean(predictions == Y) * 100\n",
    "print(f\"Training Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73e1fe-61e9-450d-a05e-57d102e1a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reference - chatgpt\n",
    "https://chatgpt.com/share/6789246e-b114-8007-978c-039cfc036b10 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
