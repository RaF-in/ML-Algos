{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f478a9e-61ef-4a13-bf20-4c4171d4caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "baab55ee-c588-4920-824a-1897e092e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open(\"shakes.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "adb19af8-bf9e-4f5b-9a8b-58fb68f4b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fcf989f9-bed1-4364-8281-994007bea566",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda s: \"\".join([itos[c] for c in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80ddbcc7-4542-4af4-b52b-e18e7ed6e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "38faa9d8-bb2c-4a74-86d9-9b87fc284dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854 111540\n"
     ]
    }
   ],
   "source": [
    "train_sz = int(len(data) * 0.9)\n",
    "train_data = data[:train_sz]\n",
    "val_data = data[train_sz:]\n",
    "print(len(train_data), len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50d50416-2e7d-4fde-9215-1b2567df9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, batch_size, block_size):\n",
    "    X, Y = None, None\n",
    "    dt = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(dt) - block_size, (batch_size, ))\n",
    "    X = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    Y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return X, Y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ef875728-e650-43fb-b905-139c61a6ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, y=None):\n",
    "        logits = self.emb(idx)\n",
    "        loss = None\n",
    "        if y != None:\n",
    "            B, T, C = logits.shape\n",
    "            logits2 = logits.view(B*T, C)\n",
    "            ys = y.view(-1)\n",
    "            loss = F.cross_entropy(logits2, ys)\n",
    "        return logits, loss\n",
    "    def generate(self, idx, max_chars):\n",
    "        for _ in range(max_chars):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, 1)\n",
    "            ix = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, ix), 1)\n",
    "        return idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "568be176-db83-4607-b981-c04dfe31651a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nXxCCPxKdiyyDhDXfdHWS:3c?$yktU. UZgTeby!Nxb\\nRDrPl&x Sdpy:qp$adiTLXLp&vT KpFMvFDxRh':z yKrHuv;P3aNh-UsxlgG?ntDbWVUfuk3rSBm vayQ$MfsMjj&aE!h,ikd3q,iysKn-\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "Xs, Ys = get_batch('train', 4, 8)\n",
    "logits, loss = model.forward(Xs, Ys)\n",
    "decode(model.generate(torch.zeros(1, 1, dtype=torch.long), 150)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9675afc0-228a-4355-8025-ea005ad9ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6626808643341064\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20000\n",
    "learning_rate = 1e-3\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "for _ in range(max_iter):\n",
    "    Xb, Yb = get_batch('train', batch_size, block_size)\n",
    "    logits, loss = model(Xb, Yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "83bf37bc-f5d2-4455-8127-0c4798f0637d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHENGLeaf te r fofay gimally a'd,\\nwed IO tobllie,-pld im s:\\nV:\\nOLANERDWAPES:\\nMooot buthat? s sthyrr y.\\nNCouthere w akiplle ind bus t a teame barais d t\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(model.generate(torch.zeros(1, 1, dtype=torch.long), 150)[0].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
