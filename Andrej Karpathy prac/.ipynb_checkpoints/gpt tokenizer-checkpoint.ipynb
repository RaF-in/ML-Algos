{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4dca1da6-7a14-4709-b92f-e72defa63933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[233, 153, 170, 229, 175]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = '''Sigh ... everybody likes to be \"pythonic\" and goes for the least characters to type. First, another criteria is readability. Second, the first test in the answer above is true not only if the dict exists and is empty, but also if test_dict is None. So use this test only when you know that the dict object exists (or when the difference does not matter). The second way also has that behavior. Only the third way barks if test_dict is None. – \n",
    "Andreas Maier\n",
    " CommentedDec 12, 2016 at 19:37 \n",
    "1\n",
    "@AndreasMaier Exactly my feeling as well. Also, python is dynamically typed. Inside a function it's common to check \"if x is non-empty dictionary, then do this; if x is non-empty numpy array, then do that\". Then the first code will fail on if x when x is numpy array – \n",
    "jf328\n",
    " CommentedDec 15, 2016 at 8:36 \n",
    "1\n",
    "@Wajih you link is still irrelevant here... See why – \n",
    "Ulysse BN\n",
    " CommentedFeb 17, 2017 at 20:44\n",
    "5\n",
    "Not upvoting this although technically correct due to concerns I share with. @AndreasMaier – \n",
    "Stunner\n",
    " CommentedDec 17, 2018 at 23:36\n",
    "@AndreasMaier and the pythonic way to solve this is to add if test_dict is not None: print(\"Dict is None\") at the beginning – \n",
    "lupodellasleppa\n",
    " CommentedSep 20, 2023 at 13:43\n",
    "Add a comment\n",
    "43\n",
    "\n",
    "Simple ways to check an empty dict are below:\n",
    "\n",
    "a = {}\n",
    "if a == {}:\n",
    "  print ('empty dict')\n",
    "if not a:\n",
    "  print ('empty dict')\n",
    "Method 1 is more strict, because when a = None, method 1 will provide the correct result, but method 2 will give an incorrect result.\n",
    "\n",
    "Share\n",
    "Improve this answer\n",
    "Follow\n",
    "edited Jan 5, 2023 at 13:05\n",
    "Gino Mempin's user avatar\n",
    "Gino Mempin\n",
    "29.8k3131 gold badges119119 silver badges166166 bronze badges\n",
    "answered Dec 11, 2018 at 10:11\n",
    "Shagun Pruthi's user avatar\n",
    "Shagun Pruthi\n",
    "2,0611818 silver badges1919 bronze badges\n",
    "This should be the accepted answer as it is the only answer differentiating between empty dict's and anything evaluating to None. – \n",
    "Wör Du Schnaffzig\n",
    " CommentedMay 2, 2024 at 9:25\n",
    "Add a comment\n",
    "39\n",
    "\n",
    "d = {}\n",
    "print(len(d.keys()))\n",
    "If the length is zero, it means that the dict is empty.\n",
    "\n",
    "Share\n",
    "Improve this answer\n",
    "Follow\n",
    "edited Jan 5, 2023 at 13:10\n",
    "Gino Mempin's user avatar\n",
    "Gino Mempin\n",
    "29.8k3131 gold badges119119 silver badges166166 bronze badges\n",
    "answered Dec 16, 2016 at 10:00\n",
    "Achilles Ram Nakirekanti's user avatar\n",
    "Achilles Ram Nakirekanti\n",
    "4,02111 gold badge2323 silver badges1313 bronze badges\n",
    "5\n",
    "While this code snippet may solve the question, including an explanation really helps to improve the quality of your post. Remember that you are answering the question for readers in the future, and those people might not know the reasons for your code suggestion. – \n",
    "DimaSan\n",
    " CommentedDec 16, 2016 at 11:43\n",
    "9\n",
    "len(dict.keys()) is equivalent to len(dict) – \n",
    "pdpAxis\n",
    " CommentedJun 4, 2020 at 18:45 \n",
    "@pdpAxis In the value it gives, though I bet the implementation of dict.__len__ is probably a bit faster. :) – \n",
    "Mateen Ulhaq\n",
    " CommentedJun 11, 2020 at 2:21\n",
    "1\n",
    "len(dict.keys()) is NOT equivalent to len(dict). The first case fails on lists and tuples, the second not. So, the first statement is more explicit. – \n",
    "Wör Du Schnaffzig\n",
    " CommentedMay 2, 2024 at 9:30 \n",
    "Add a comment\n",
    "10\n",
    "\n",
    "A dictionary can be automatically cast to boolean which evaluates to False for empty dictionary and True for non-empty dictionary.\n",
    "\n",
    "if myDictionary: non_empty_clause()\n",
    "else: empty_clause()\n",
    "If this looks too idiomatic, you can also test len(myDictionary) for zero, or set(myDictionary.keys()) for an empty set, or simply test for equality with {}.\n",
    "\n",
    "The isEmpty function is not only unnecessary but also your implementation has multiple issues that I can spot prima-facie.\n",
    "\n",
    "The return False statement is indented one level too deep. It should be outside the for loop and at the same level as the for statement. As a result, your code will process only one, arbitrarily selected key, if a key exists. If a key does not exist, the function will return None, which will be cast to boolean False. Ouch! All the empty dictionaries will be classified as false-nagatives.\n",
    "If the dictionary is not empty, then the code will process only one key and return its value cast to boolean. You cannot even assume that the same key is evaluated each time you call it. So there will be false positives.\n",
    "Let us say you correct the indentation of the return False statement and bring it outside the for loop. Then what you get is the boolean OR of all the keys, or False if the dictionary empty. Still you will have false positives and false negatives. Do the correction and test against the following dictionary for an evidence.\n",
    "myDictionary={0:'zero', '':'Empty string', None:'None value', False:'Boolean False value', ():'Empty tuple'}\n",
    "\n",
    "Share\n",
    "Improve this answer\n",
    "Follow\n",
    "edited Jan 16, 2019 at 3:33\n",
    "answered Jan 14, 2019 at 10:25\n",
    "Della's user avatar\n",
    "Della\n",
    "1,64833 gold badges2626 silver badges5050 bronze badges\n",
    "Add a comment\n",
    "8\n",
    "\n",
    "1st Way\n",
    "len(given_dic_obj) \n",
    "It returns 0 if there are no elements. Else, returns the size of the dictionary.'''\n",
    "ids = list(map(int, \"陪審制（英: Jury system）は、刑事訴訟や民事訴訟の審理に際して、民間から無作為で選ばれた陪審員によって構成される（裁判官を含まない）合議体が評議によって事実認定を行う司法制度である。陪審員の人数は6～ 12名である場合が多く、その合議体を「陪審」という。陪審は、刑事事件では原則として被告人の有罪・無罪について、民事事件では被告の責任の有無や損害賠償額等について判断する。\".encode(\"utf-8\")))\n",
    "ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e551a04-04ba-4728-a4bc-6d538cad10c6",
   "metadata": {},
   "source": [
    "1. First build a dictionary of maximum pair occurrence - getStats method\n",
    "2. Replace all the occurences with the new one - Merge method\n",
    "3. Run 20 times to replace top 20 occurences\n",
    "4. Write method for decode and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dbb941b-9ffe-4754-9bbc-47fdb403706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 129) 54\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ids):\n",
    "    mp = {}\n",
    "    for it1, it2 in zip(ids, ids[1:]):\n",
    "        mp[(it1, it2)] = mp.get((it1, it2), 0) + 1\n",
    "    return mp\n",
    "stats = get_stats(ids)\n",
    "pair = max(stats, key=stats.get)\n",
    "print(pair, stats[pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96de7d94-a5d2-4de2-99ad-518846464d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 13, 14, 15, 55, 12, 55]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge(pair, new_id, ids):\n",
    "    new_ids = []\n",
    "    idx = 0\n",
    "    while idx + 1 < len(ids):\n",
    "        if pair[0] == ids[idx] and pair[1] == ids[idx + 1]:\n",
    "            new_ids.append(new_id)\n",
    "            idx += 2\n",
    "        else:\n",
    "            new_ids.append(ids[idx])\n",
    "            idx += 1\n",
    "    return new_ids\n",
    "merge((10, 12), 55, [10, 12, 13, 14, 15, 10, 12, 12, 10, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "505035f3-a1cb-4203-bae4-7d97984aaefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "mp = {}\n",
    "print(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25a7c1bd-b155-4869-a524-59d02d6cb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace from ids first 10 occurences\n",
    "current_ids = ids\n",
    "merge_items = {}\n",
    "new_id = 255\n",
    "for i in range(10):\n",
    "    stats = get_stats(current_ids)\n",
    "    if not stats:\n",
    "        break\n",
    "    pair_to_replace = max(stats, key=stats.get)\n",
    "    new_id = new_id + 1\n",
    "    current_ids = merge(pair_to_replace, new_id, current_ids)\n",
    "    merge_items[pair_to_replace] = new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5346089e-859d-42bc-90a5-bd29fa0949ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'陪審制（英: Jury system）は、刑事訴訟や民事�'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for pair, val in merge_items.items():\n",
    "    vocab[val] = vocab[pair[0]] + vocab[pair[1]]\n",
    "def decode(encoded_tokens):\n",
    "    raw_bytes = b\"\".join(vocab[token] for token in encoded_tokens)\n",
    "    decoded_text = raw_bytes.decode('utf-8', errors='replace')\n",
    "    return decoded_text\n",
    "decode(ids[0:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9469bbe1-3b68-4476-814e-c07e557a5ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(text):\n",
    "    encoded_ids = list(map(int, text.encode(\"utf-8\")))\n",
    "    while True:\n",
    "        stats = get_stats(encoded_ids)\n",
    "        pair = min(stats, key=lambda p: merge_items.get(p, float(\"inf\")))\n",
    "        if pair not in merge_items:\n",
    "            break\n",
    "        encoded_ids = merge(pair, merge_items[pair], encoded_ids)\n",
    "    return encoded_ids\n",
    "decode(encode(text_data)) == text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698feb30-c0f2-4b7b-bc45-6722b8b35aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next to do\n",
    "1. Andrej Karpathy exercise on tokenizer\n",
    "2. Practice Sentence Piece code - see Andrej examples\n",
    "3. Answer the following questions  \n",
    "Why can't LLM spell words? Tokenization.\n",
    "- Because if the word is treated as a single token, then LLM actually not good because LLM works across tokens. Not what is inside a token\n",
    "Why can't LLM do super simple string processing tasks like reversing a string? Tokenization.\n",
    "- For the same reason above\n",
    "Why is LLM worse at non-English languages (e.g. Japanese)? Tokenization.\n",
    "- Because of the number of token generation. LLM usually generates more tokens for non english sentences. As a result for a fixed context lenght LLM knows very little \n",
    "information to predict the next word\n",
    "Why is LLM bad at simple arithmetic? Tokenization.\n",
    "- Digits are tokenized randomly and it is not possbile for LLM to store positional information of the digits. For arithmatic operations we have to know the positions of \n",
    "the digits. \n",
    "Why did GPT-2 have more than necessary trouble coding in Python? Tokenization.\n",
    "    - Due to the same reason of non english. GPT - 2 treats each single space as a single token. But later in GPT-4 this problem was addressed. \n",
    "Why did my LLM abruptly halt when it sees the string \"<|endoftext|>\"? Tokenization.\n",
    "What is this weird warning I get about a \"trailing whitespace? Tokenization.\n",
    "- traling white space actually adds 220 at the end. But during training LLM has not seen this pattern as always ' word' is seen by LLM. Space is considered inside the next\n",
    "word. \n",
    "Why the LLM break if I ask it about \"SolidGoldMagikarp\"? Tokenization. \n",
    "- SolidGoldMagikarp is a reddit user who has posted a lot. As a result during tokenization training with BPE this word is treated as an individual token. But in LLM training\n",
    "phase LLM has not seen this word for a single time. So the embedding table entries never got updated for this word. So initial random numbers still exist for this word.\n",
    "As a result LLM gives completely random results as the embedding has not learnt anything from training data. \n",
    "Why should I prefer to use YAML over JSON with LLMs? Tokenization.\n",
    "- Yaml is very concise and precise due to tokenization and produces less tokens than Json representation. So if we are paying over context length, we should choose YAML. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
